---
title: "KNN Regression"
author: "Moira Renata"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
set.seed(1000)

bike_spec_1 <- nearest_neighbor(weight_func = "rectangular", neighbors = tune()) |> 
       set_engine("kknn") |>
       set_mode("regression") 

bike_recipe_1 <- recipe(bike_count ~ temperature, data = bike_training) |>
       step_scale(all_predictors()) |>
       step_center(all_predictors())

bike_vfold_1 <- vfold_cv(bike_training, v = 10, strata = bike_count)

bike_workflow_1 <- workflow() |>
  add_recipe(bike_recipe_1) |>
  add_model(bike_spec_1)

gridvals <- tibble(neighbors = seq(from = 1, to = 100))

bike_results_1 <- bike_workflow_1 |>
  tune_grid(resamples = bike_vfold_1, grid = gridvals) |>
  collect_metrics() 

bike_min_1 <- bike_results_1 |>
    filter(.metric == "rmse") |>
    arrange(mean) |> 
    slice(1)
bike_min_1
```

We find that 27 neighbours give us the lowest $RMSE$ value. To test our model, we will assess its $RMSPE$ by creating a model using 27 neighbors and then assess its accuracy on the testing data set. First we pull the best value for neighbors and store it in the object k_min_1.
We then repeat the workflow analysis with a new model trained with the best neighbor value. We then use `predict` function to make predictions using the test data, and use the `metrics` function to create a summary of the model's regression accuracy.

```{r setup, include=FALSE}
k_min_1 <- bike_min_1 |>
          pull(neighbors)

bike_best_spec_1 <- nearest_neighbor(weight_func = "rectangular", neighbors = k_min_1) |>
          set_engine("kknn") |>
          set_mode("regression")

bike_best_fit_1 <- workflow() |>
          add_recipe(bike_recipe_1) |>
          add_model(bike_best_spec_1) |>
          fit(data = bike_training)

bike_summary_1 <- bike_best_fit_1 |>
           predict(bike_testing) |>
           bind_cols(bike_testing) |>
           metrics(truth = bike_count, estimate = .pred) |>
           filter(.metric == "rmse")       
bike_summary_1
```

The $RMSPE$ value is found to be 6092.35. Below, we create a plot to better visualize the relation between bike count and temperature with our best neighbors value. Before creating the plot, we use the predict function on the workflow analysis that contained the best neighbor value to create predictions for the training data.

Figure 6 shows the data with the best fit curve (blue), which estimates the number of bikes rented per day based on temperature. 

Using the same procedure as above, we will now create a K-NN regression model that uses solar radiation as the predictor of rented bike counts. 

```{r setup, include=FALSE}
set.seed(1004)

bike_spec_2 <- nearest_neighbor(weight_func = "rectangular", neighbors = tune()) |> 
       set_engine("kknn") |>
       set_mode("regression") 

bike_recipe_2 <- recipe(bike_count ~ solar_radiation, data = bike_training) |>
       step_scale(all_predictors()) |>
       step_center(all_predictors())

bike_vfold_2 <- vfold_cv(bike_training, v = 10, strata = bike_count)

bike_workflow_2 <- workflow() |>
  add_recipe(bike_recipe_2) |>
  add_model(bike_spec_2)

gridvals <- tibble(neighbors = seq(from = 1, to = 100))

bike_results_2 <- bike_workflow_2 |>
  tune_grid(resamples = bike_vfold_2, grid = gridvals) |>
  collect_metrics() 

bike_min_2 <- bike_results_2 |>
    filter(.metric == "rmse") |>
    arrange(mean) |> 
    slice(1)
bike_min_2
```

```{r setup, include=FALSE}
k_min_2 <- bike_min_2 |>
          pull(neighbors)

bike_best_spec_2 <- nearest_neighbor(weight_func = "rectangular", neighbors = k_min_2) |>
          set_engine("kknn") |>
          set_mode("regression")

bike_best_fit_2 <- workflow() |>
          add_recipe(bike_recipe_2) |>
          add_model(bike_best_spec_2) |>
          fit(data = bike_training)

bike_summary_2 <- bike_best_fit_2 |>
           predict(bike_testing) |>
           bind_cols(bike_testing) |>
           metrics(truth = bike_count, estimate = .pred) |>
           filter(.metric == "rmse")       
bike_summary_2
```

Using K = 38, the $RMSE$ value is found to be 6383.16 and the $RMSPE$ value is found to be 7088.66, which are both higher than the values we obtained using temperature as the only predictor. This demonstrates that similar to our linear regression analysis, the K-NN regression model that uses temperature as the only predictor is again more accurate than the model that uses solar radiation when estimating the number of bikes rented per day. 

Below, we create a scatter plot to show rented bike count vs solar radiation with our predicted model curve (shown in blue).

```{r setup, include=FALSE}
set.seed(1008)

bike_spec_3 <- nearest_neighbor(weight_func = "rectangular", neighbors = tune()) |> 
       set_engine("kknn") |>
       set_mode("regression") 

bike_recipe_3 <- recipe(bike_count ~ temperature + solar_radiation, data = bike_training) |>
       step_scale(all_predictors()) |>
       step_center(all_predictors())

bike_vfold_3 <- vfold_cv(bike_training, v = 10, strata = bike_count)

bike_workflow_3 <- workflow() |>
  add_recipe(bike_recipe_3) |>
  add_model(bike_spec_3)

gridvals <- tibble(neighbors = seq(from = 1, to = 100))

bike_results_3 <- bike_workflow_3 |>
  tune_grid(resamples = bike_vfold_3, grid = gridvals) |>
  collect_metrics() 

bike_min_3 <- bike_results_3 |>
    filter(.metric == "rmse") |>
    arrange(mean) |> 
    slice(1)
bike_min_3
```

The $RMSE$ value is found to be 3556.36 and the $RMSPE$ value is found to be 3782.12, which are the lowest error values out of the three K-NN models we created.

# Discussion
The question we were trying to answer was: in 2018, in Seoul, Korea, what were the strongest environmental predictors of the quantity of bikes rented out each day, and how effectively can those predictors be used to predict the number of bikes rented out on a given day given the environmental conditions of that day? We narrowed down the data to use the two predictors with the strongest correlation coefficients, temperature and solar radiation, which had correlation coefficients of 0.764 and 0.750, respectively.

Overall, the $RMSPE$ values for both K nearest neighbours regression and linear regression were lowest when we used both solar radiation and temperature as predictors. We also found that the K-NN regression models have lower $RMSPE$ values than that of linear regression, so the models that used K-NN regression were more accurate. We can therefore conclude that the K-NN regression model with two predictors (temperature and solar radiation) with 9 neighbours is the best model, since it is most accurate with the lowest $RMSPE$ (3782). This means that when given the temperature and solar radiation of a given day, the predicted number of bikes rented  will differ from the actual value by an average of 3782 bikes. This shows that the prediction model is fairly accurate because when we look at the range of bike counts (~35,000) as shown in Figure 1, 3782 is not that significant.  

According to a number of articles on biking in South Korea, it was found that cycling is a very common mode of transportation and that Korea is one of the best places to bike. Hall states that "at any time of year, South Korea is an ideal country to explore by bike" (2022). For these reasons, we expected harsh weather conditions such as snowfall and rainfall to not contain very strong correlations and according to the bar graph created, they both had fairly weak correlations below 0.3. However, values like temperature and solar radiation influence bike rentals. Temperature was expected, but not solar radiation. According to Jensen, "... it's cold enough to be dangerous or unpleasant if you're not prepared," (2022). Cold weather is one of the only deterrents in Seoul, Korea, because it can be dangerous to bike without the proper equipment. We can predict that people would opt for other transportation options when the temperature drops.

Our findings demonstrate that people are more likely to ride bikes in warmer temperatures and when there is higher solar radiation. This information is useful to bike sharing companies because they can offer discounts during times when bike rentals are low (such as colder temperatures and non sunny days), in order to increase users and increase profits. Additionally, these findings demonstrate that bike rental businesses tend to do well in Seoul because harsh/extreme changes in precipitation don’t have much of an effect on customer usage. Therefore, this information could be useful for investors or people who would like to open a new bike rental company because Seoul is a place that could potentially be very successful. These findings could also pose questions about reduced carbon footprint for Korea in the future, since weather doesn't deter people from biking. In addition, it could be useful to study the environmental and social impacts of bike sharing in Korea. Our findings lead to further inquiries, including whether there are impacts/rises in life expectancy as people use bikes more and whether people become less stressed due to constant exposure to the positive and healthy effects that come from bike riding in Seoul.

# References

Cricchio, Michaela. “How to Rent Bikes in Seoul: Bike Ride on the Han River or Just Get from a to B.” The Soul of Seoul, 10 Nov. 2020, thesoulofseoul.net/how-to-rent-bike-in-seoul/.

Hall, Jarrod. “Winter Cycling in South Korea - Tips & Gear to Keep Riding in Freezing Temperatures.” Korean Rooftop, www.koreanrooftop.com/blog/winter-cycling-in-korea#:~:text=Winter%20cycling%20in%20Korea%20is. Accessed 5 Dec. 2022.

Jensen, Erik. “Cycling in South Korea: 5 Best Paths, When to Go, and Travel Tips.” Bookmundi.com, 11 May 2021, www.bookmundi.com/t/cycling-in-south-korea-5-best-paths. Accessed 4 Dec. 2022.

Joo-Heon, Kim. “Seoul's Public Bike Rental Service Becomes Popular Public Transport System.” AJU   Business Daily, 27 Apr. 2022, https://www.ajudaily.com/view/20220427094305098. 


